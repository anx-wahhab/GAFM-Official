{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:58:37.482643Z",
     "start_time": "2024-06-14T09:58:36.288909Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "BASE_DIR = '..'\n",
    "RANDOM_SEED = 7 # for reproducibility\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "\n",
    "# these relate to training the CNN to predict nightlights\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, 'data', 'images')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:58:42.093856Z",
     "start_time": "2024-06-14T09:58:42.087408Z"
    }
   },
   "id": "96c1444b079ff708",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(os.path.join(PROCESSED_DIR, 'finalized_df.csv'))",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:58:55.924739Z",
     "start_time": "2024-06-14T09:58:55.912402Z"
    }
   },
   "id": "f10513d5b798a797",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "df.sample(10)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:58:57.128271Z",
     "start_time": "2024-06-14T09:58:57.111753Z"
    }
   },
   "id": "b957790bfb09c28b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     income_per_cluster  cluster_lat  cluster_long  nightlights    district  \\\n",
       "22           229.227513    32.250834     73.916430     1.434259  gujranwala   \n",
       "9            219.954171    32.211450     73.976467     1.383935  gujranwala   \n",
       "111          328.012346    32.093297     74.276652     1.951389  gujranwala   \n",
       "56           274.179012    31.896375     74.096541     1.752130  gujranwala   \n",
       "16           224.757425    31.975144     73.916430     1.434259  gujranwala   \n",
       "184          584.185185    31.935759     74.576838     2.706250  gujranwala   \n",
       "12           221.955026    32.329603     73.976467     1.383935  gujranwala   \n",
       "60           277.659612    31.856990     74.156578     1.844676  gujranwala   \n",
       "45           257.462963    32.329603     74.096541     1.752130  gujranwala   \n",
       "19           227.731922    32.093297     73.916430     1.434259  gujranwala   \n",
       "\n",
       "      dist_lat  dist_long                                       cluster_name  \n",
       "22   32.168056  74.120556  32.250834315384616_73.91642986923078_32.168055...  \n",
       "9    32.168056  74.120556  32.21144992307693_73.97646695384616_32.1680555...  \n",
       "111  32.168056  74.120556  32.09329674615385_74.27665237692308_32.1680555...  \n",
       "56   32.168056  74.120556  31.896374784615386_74.09654112307693_32.168055...  \n",
       "16   32.168056  74.120556  31.97514356923077_73.91642986923078_32.1680555...  \n",
       "184  32.168056  74.120556  31.935759176923078_74.5768378_32.16805556_74.1...  \n",
       "12   32.168056  74.120556  32.3296031_73.97646695384616_32.16805556_74.12...  \n",
       "60   32.168056  74.120556  31.856990392307694_74.15657820769232_32.168055...  \n",
       "45   32.168056  74.120556  32.3296031_74.09654112307693_32.16805556_74.12...  \n",
       "19   32.168056  74.120556  32.09329674615385_73.91642986923078_32.1680555...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_per_cluster</th>\n",
       "      <th>cluster_lat</th>\n",
       "      <th>cluster_long</th>\n",
       "      <th>nightlights</th>\n",
       "      <th>district</th>\n",
       "      <th>dist_lat</th>\n",
       "      <th>dist_long</th>\n",
       "      <th>cluster_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>229.227513</td>\n",
       "      <td>32.250834</td>\n",
       "      <td>73.916430</td>\n",
       "      <td>1.434259</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.250834315384616_73.91642986923078_32.168055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>219.954171</td>\n",
       "      <td>32.211450</td>\n",
       "      <td>73.976467</td>\n",
       "      <td>1.383935</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.21144992307693_73.97646695384616_32.1680555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>328.012346</td>\n",
       "      <td>32.093297</td>\n",
       "      <td>74.276652</td>\n",
       "      <td>1.951389</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.09329674615385_74.27665237692308_32.1680555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>274.179012</td>\n",
       "      <td>31.896375</td>\n",
       "      <td>74.096541</td>\n",
       "      <td>1.752130</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>31.896374784615386_74.09654112307693_32.168055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>224.757425</td>\n",
       "      <td>31.975144</td>\n",
       "      <td>73.916430</td>\n",
       "      <td>1.434259</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>31.97514356923077_73.91642986923078_32.1680555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>584.185185</td>\n",
       "      <td>31.935759</td>\n",
       "      <td>74.576838</td>\n",
       "      <td>2.706250</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>31.935759176923078_74.5768378_32.16805556_74.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>221.955026</td>\n",
       "      <td>32.329603</td>\n",
       "      <td>73.976467</td>\n",
       "      <td>1.383935</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.3296031_73.97646695384616_32.16805556_74.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>277.659612</td>\n",
       "      <td>31.856990</td>\n",
       "      <td>74.156578</td>\n",
       "      <td>1.844676</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>31.856990392307694_74.15657820769232_32.168055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>257.462963</td>\n",
       "      <td>32.329603</td>\n",
       "      <td>74.096541</td>\n",
       "      <td>1.752130</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.3296031_74.09654112307693_32.16805556_74.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>227.731922</td>\n",
       "      <td>32.093297</td>\n",
       "      <td>73.916430</td>\n",
       "      <td>1.434259</td>\n",
       "      <td>gujranwala</td>\n",
       "      <td>32.168056</td>\n",
       "      <td>74.120556</td>\n",
       "      <td>32.09329674615385_73.91642986923078_32.1680555...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split images into train and validation sets.\n",
    "The ratio shall be 80 20 => Train Valid => 160 40 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bb93eee051a4120"
  },
  {
   "cell_type": "code",
   "source": [
    "districts = df['district'].unique()\n",
    "\n",
    "for district in districts:\n",
    "\n",
    "    filtered_df = df[df['district'] == district].reset_index().drop('index', axis=1)\n",
    "    X = filtered_df.drop('nightlights', axis=1)  # Assuming 'target_column' is the name of your target variable\n",
    "    y = filtered_df['nightlights']\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)  # Split into 80% train, 20% val\n",
    "\n",
    "    print('copying training data for {}'.format(district))\n",
    "    for im_name, nl in zip(X_train['cluster_name'], y_train):\n",
    "        src = os.path.join(IMAGE_DIR, district, im_name)\n",
    "        dest = os.path.join(IMAGE_DIR, district, 'train')\n",
    "        os.makedirs(dest, exist_ok=True)  # Create destination directory if it doesn't exist\n",
    "        shutil.copy(src, dest)\n",
    "    \n",
    "    print('copying test images for {}'.format(district))\n",
    "    for im_name, nl in tqdm(zip(X_val['cluster_name'], y_val), total=2):\n",
    "        src = os.path.join(IMAGE_DIR, district, im_name)\n",
    "        dest = os.path.join(IMAGE_DIR, district, 'test')\n",
    "        os.makedirs(dest, exist_ok=True)  # Create destination directory if it doesn't exist\n",
    "        shutil.copy(src, dest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:56:16.321952Z",
     "start_time": "2024-06-14T09:56:16.267677Z"
    }
   },
   "id": "3c752eacd436811f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying training data for gujranwala\n",
      "here !!!\n",
      "..\\data\\images\\gujranwala\\train\n",
      "..\\data\\images\\gujranwala\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\images\\\\gujranwala\\\\32.17206553076923_74.39672654615386_32.16805556_74.12055556_2.772407407407407.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(dest))\n\u001B[0;32m     21\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(dest, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Create destination directory if it doesn't exist\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m     \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcopying test images for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(district))\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m im_name, nl \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mzip\u001B[39m(X_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcluster_name\u001B[39m\u001B[38;5;124m'\u001B[39m], y_val), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GENERAL\\Lib\\shutil.py:435\u001B[0m, in \u001B[0;36mcopy\u001B[1;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(dst):\n\u001B[0;32m    434\u001B[0m     dst \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dst, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(src))\n\u001B[1;32m--> 435\u001B[0m \u001B[43mcopyfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_symlinks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_symlinks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    436\u001B[0m copymode(src, dst, follow_symlinks\u001B[38;5;241m=\u001B[39mfollow_symlinks)\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dst\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GENERAL\\Lib\\shutil.py:260\u001B[0m, in \u001B[0;36mcopyfile\u001B[1;34m(src, dst, follow_symlinks)\u001B[0m\n\u001B[0;32m    258\u001B[0m     os\u001B[38;5;241m.\u001B[39msymlink(os\u001B[38;5;241m.\u001B[39mreadlink(src), dst)\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 260\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fsrc:\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    262\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(dst, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fdst:\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;66;03m# macOS\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '..\\\\data\\\\images\\\\gujranwala\\\\32.17206553076923_74.39672654615386_32.16805556_74.12055556_2.772407407407407.png'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training - Nightlights Prediction",
   "id": "61012debd782f0c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T07:00:14.896865Z",
     "start_time": "2024-06-26T07:00:03.913668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms"
   ],
   "id": "a19ab20cdf585dbb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T07:00:14.908755Z",
     "start_time": "2024-06-26T07:00:14.899771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'GAFM_Framework'\n",
    "model_path = os.path.join('..', 'fine_tuned_models', model_name)\n",
    "fig_path = os.path.join(model_path, 'figures')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ],
   "id": "6a130e0582911f83",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data directory\n",
    "district = 'gujranwala'\n",
    "data_dir = os.path.join('..', 'data', 'images', district)\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "valid_dir = os.path.join(data_dir, \"valid\")"
   ],
   "id": "6a14a71c346773cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AuxiliaryBranch(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=None):\n",
    "        super(AuxiliaryBranch, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        if self.downsample is not None:\n",
    "            # Correctly adjust downsample to expect the right input channels\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "class GFMM(nn.Module):\n",
    "    def __init__(self, in_channels_main, in_channels_aux):\n",
    "        super(GFMM, self).__init__()\n",
    "        self.batch_norm_main = nn.BatchNorm2d(in_channels_main)\n",
    "        self.batch_norm_aux = nn.BatchNorm2d(in_channels_aux)\n",
    "        self.conv_g = nn.Conv2d(in_channels_main + in_channels_aux, in_channels_main, kernel_size=1)\n",
    "        self.conv_f = nn.Conv2d(in_channels_main + in_channels_aux, in_channels_main, kernel_size=1)\n",
    "        self.conv_out = nn.Conv2d(in_channels_main, in_channels_main, kernel_size=1)\n",
    "\n",
    "    def forward(self, fm, fa):\n",
    "        # Normalize features\n",
    "        fm_norm = self.batch_norm_main(fm)\n",
    "        fa_norm = self.batch_norm_aux(fa)\n",
    "        # Concatenate features\n",
    "        combined = torch.cat((fm_norm, fa_norm), dim=1)\n",
    "\n",
    "        # Gating mechanism\n",
    "        fg = torch.sigmoid(self.conv_g(combined))\n",
    "        fr = self.conv_f(combined)\n",
    "\n",
    "        # Output feature\n",
    "        fo = self.conv_out(fg * fm_norm + (1 - fg) * fr)\n",
    "\n",
    "        return fo\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_channels, _, _ = x.size()\n",
    "        se = self.global_avg_pool(x).view(batch_size, num_channels)\n",
    "        se = F.relu(self.fc1(se))\n",
    "        se = torch.sigmoid(self.fc2(se)).view(batch_size, num_channels, 1, 1)\n",
    "        return x * se\n",
    "\n",
    "class SEBottleneckWithGFMM(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n",
    "        super(SEBottleneckWithGFMM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SEBlock(planes * self.expansion, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        # Correctly match the number of input channels for downsample_aux\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            downsample_aux = nn.Sequential(\n",
    "                nn.Conv2d(planes * self.expansion, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion),\n",
    "            )\n",
    "        else:\n",
    "            downsample_aux = nn.Sequential(\n",
    "                nn.Conv2d(planes * self.expansion, planes * self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion),\n",
    "            )\n",
    "\n",
    "        self.aux_branch = AuxiliaryBranch(inplanes, planes * self.expansion, downsample=downsample_aux)\n",
    "        self.gfmm = GFMM(planes * self.expansion, planes * self.expansion)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # Main branch\n",
    "        main_branch_out = self.conv1(x)\n",
    "        main_branch_out = self.bn1(main_branch_out)\n",
    "        main_branch_out = self.relu(main_branch_out)\n",
    "        main_branch_out = self.conv2(main_branch_out)\n",
    "        main_branch_out = self.bn2(main_branch_out)\n",
    "        main_branch_out = self.relu(main_branch_out)\n",
    "        main_branch_out = self.conv3(main_branch_out)\n",
    "        main_branch_out = self.bn3(main_branch_out)\n",
    "        # SE block on the main branch\n",
    "        main_branch_out = self.se(main_branch_out)\n",
    "        # Auxiliary branch\n",
    "        aux_branch_out = self.aux_branch(x)\n",
    "        # Combine outputs from main and auxiliary branches in GFMM\n",
    "        combined_out = self.gfmm(main_branch_out, aux_branch_out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        # Combine with residual and apply ReLU\n",
    "        out = combined_out + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class SEResNet50WithGFMM(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(SEResNet50WithGFMM, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(SEBottleneckWithGFMM, 64, 3)\n",
    "        self.layer2 = self._make_layer(SEBottleneckWithGFMM, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(SEBottleneckWithGFMM, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(SEBottleneckWithGFMM, 512, 3, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * SEBottleneckWithGFMM.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "7c7108c73e1a9f47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    # Inside your RegressionDataset class __getitem__ method\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.file_list[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor([get_label_from_filename(self.file_list[idx])], dtype=torch.float32)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    label_str = filename.split('_')[4][:-4]\n",
    "\n",
    "    try:\n",
    "        label = float(label_str)\n",
    "        return label\n",
    "    except ValueError:\n",
    "        print(f\"Error extracting label from filename {filename}. Setting label to 0.\")\n",
    "        return 0.0"
   ],
   "id": "48f8d62d33fe1af8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define transforms for training and validation data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ],
   "id": "e1bdc9db463f8a25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 16\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {\n",
    "    x: RegressionDataset(root_dir=os.path.join(data_dir, x), transform=data_transforms[x])\n",
    "    for x in tqdm(['train', 'valid'])\n",
    "}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in tqdm(['train', 'valid'])\n",
    "}"
   ],
   "id": "4de99457f6cfb412"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create the custom ResNet-50 model with SE blocks\n",
    "model = SEResNet50WithGFMM(num_classes=1)\n",
    "\n",
    "# Freeze all layers except the last few\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)"
   ],
   "id": "82be65f5b31eac7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_model_regression(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    best_r2 = -float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    train_r2 = []\n",
    "    valid_losses = []\n",
    "    valid_r2 = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_r2 = 0.0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.float().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    r2 = r2_score(labels.cpu().numpy(), outputs.cpu().detach().numpy())\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_r2 += r2 * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_r2 = running_r2 / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} R-squared: {:.4f}'.format(phase, epoch_loss, epoch_r2))\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_r2.append(epoch_r2)\n",
    "            else:\n",
    "                valid_losses.append(epoch_loss)\n",
    "                valid_r2.append(epoch_r2)\n",
    "\n",
    "            if phase == 'valid' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_r2 = epoch_r2\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:.4f} Best R-squared: {:.4f}'.format(best_loss, best_r2))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, train_losses, valid_losses, train_r2, valid_r2"
   ],
   "id": "303b0e71b48c28c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device:', device)\n",
    "model = model.to(device)"
   ],
   "id": "bbd1a19cd8ce22a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train and evaluate for regression\n",
    "model, train_losses, valid_losses, train_r2, valid_r2 = train_model_regression(model, dataloaders_dict, criterion, optimizer, num_epochs=100)"
   ],
   "id": "98fff1fb7f7fdd26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize losses\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(fig_path, 'loss.png'))\n",
    "plt.show()\n",
    "\n",
    "# Visualize R-squared values\n",
    "plt.plot(train_r2, label='Training R-squared')\n",
    "plt.plot(valid_r2, label='Validation R-squared')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R-squared')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(fig_path, 'r2.png'))\n",
    "plt.show()"
   ],
   "id": "1d54f8c19c9b6438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_accuracy_range(r2_scores, mode):\n",
    "    r2_scores_np = np.array(r2_scores)\n",
    "    min_r2 = np.min(r2_scores_np)\n",
    "    max_r2 = np.max(r2_scores_np)\n",
    "    avg_r2 = np.mean(r2_scores_np)\n",
    "\n",
    "    print(f\"Minimum {mode} R-squared:{min_r2:.2f}\")\n",
    "    print(f\"Maximum {mode} R-squared:{max_r2:.2f}\")\n",
    "    print(f\"Average {mode} R-squared:{avg_r2:.2f}\",'\\n')\n",
    "\n",
    "\n",
    "compute_accuracy_range(train_r2, mode='training')\n",
    "compute_accuracy_range(valid_r2, mode='testing')"
   ],
   "id": "902e59278d884a28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_save_path = os.path.join(model_path, model_name + '.pt')\n",
    "torch.save(model, model_save_path)\n",
    "print('Model saved successfully !!')"
   ],
   "id": "7443393b242e9066"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
