{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = 'resnet50'\n",
    "model_path = os.path.join('..', 'fine_tuned_models', model_name)\n",
    "model = torch.load(model_path)"
   ],
   "id": "f2d09c993dfcc22d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])",
   "id": "c5d0434c0361ebde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Extraction",
   "id": "2b7d0b8c57b4c9ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_features(model, device, root_dir):\n",
    "\n",
    "    # Define transformations to preprocess the input image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),  # Resize to the input size of the model\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),           # Convert image to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    # Initialize an empty list to store rows\n",
    "    rows = []\n",
    "\n",
    "    # Loop through each subdirectory in the root directory\n",
    "    for subdir in ['train', 'valid']:\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Loop through each image file in the subdirectory\n",
    "            for file_name in tqdm(os.listdir(subdir_path)):\n",
    "                file_path = os.path.join(subdir_path, file_name)\n",
    "\n",
    "                # Load and preprocess the image\n",
    "                image = Image.open(file_path).convert('RGB')\n",
    "                input_tensor = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "                # Move the input tensor to the appropriate device (GPU if available)\n",
    "                input_tensor = input_tensor.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_tensor)\n",
    "\n",
    "                # Extract features\n",
    "                feats = np.squeeze(output).cpu().numpy().flatten()\n",
    "                # Append image name and features to the list\n",
    "                row_data = [file_name] + list(feats)\n",
    "                rows.append(row_data)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    result_df = pd.DataFrame(rows)\n",
    "\n",
    "    return result_df"
   ],
   "id": "31430dea91b188d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "device"
   ],
   "id": "92cd781d62f542c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data directory\n",
    "district = 'gujranwala'\n",
    "data_dir = os.path.join('..', 'data', 'images', district)\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "valid_dir = os.path.join(data_dir, \"valid\")"
   ],
   "id": "9010573adca23818"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data directory\n",
    "district = 'gujranwala'\n",
    "imgs_path = os.path.join('..', 'data', 'images', district)\n",
    "img_feats = extract_features(feature_extractor, device, imgs_path)"
   ],
   "id": "12364629a50353f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "img_feats.rename({0:'cluster_name'}, axis=1, inplace=True)\n",
    "img_feats['cluster_name'] = img_feats['cluster_name'].str.rsplit('_', n=1).str[0]\n",
    "img_feats"
   ],
   "id": "b3923c9a8ff18787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "img_feats['cluster_name'][0]",
   "id": "68f484b8b96f87c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_path = os.path.join('..', 'data', 'processed', 'finalized_df.csv')\n",
    "df = pd.read_csv(df_path)\n",
    "df.sample(10)"
   ],
   "id": "ae2548e20aed232e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "joined_df = df.set_index('cluster_name').join(img_feats.set_index('cluster_name'), how='inner').reset_index(drop=True)\n",
    "joined_df.sample(10)"
   ],
   "id": "24ad3f732e030e4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_save_path = os.path.join(model_path, 'processed_data')\n",
    "os.makedirs(data_save_path, exist_ok=True)\n",
    "file_path = os.path.join(data_save_path, 'feature_indexed_' + model_name + '.csv')\n",
    "joined_df.to_csv(file_path, index=False)"
   ],
   "id": "460b82245b4baf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Pre-Processing",
   "id": "55155e779deb76d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "4ca37289d78083a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_path = os.path.join('..', 'fine_tuned_models', model_name)",
   "id": "ebb17b49a04c255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = 'resnet50'\n",
    "root_path = os.path.join('..', 'fine_tuned_models', model_name, 'processed_data')\n",
    "file_path = os.path.join(root_path, 'feature_indexed_' + model_name + '.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df.sample(10)"
   ],
   "id": "2a8f07fa87e3105a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.shape",
   "id": "f3e7f1d3d313a793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.columns",
   "id": "167dc99a26933950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.drop([\n",
    "    'district', 'dist_lat', 'dist_lon', 'cluster_lat',\n",
    "    'cluster_lon', 'nightlights', 'labels'\n",
    "], axis=1, inplace=True)"
   ],
   "id": "ba9a8326d9f19c7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.shape",
   "id": "4d9f2e4257800f10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.columns",
   "id": "d740efa2d3dc0f0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['income_per_cluster'].is_monotonic_increasing",
   "id": "25996906608f46e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.boxplot(df['income_per_cluster'])",
   "id": "9038370a32df865b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def replace_outliers_with_closest(data_):\n",
    "    # Calculate the inter quartile range (IQR)\n",
    "    q1 = np.percentile(data_, 25)\n",
    "    q3 = np.percentile(data_, 75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Replace outliers with the closest values within the IQR\n",
    "    replaced_data = np.where(data_ < lower_bound, q1, data_)\n",
    "    replaced_data = np.where(replaced_data > upper_bound, q3, replaced_data)\n",
    "\n",
    "    return replaced_data"
   ],
   "id": "3e7516cd9ac09297"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "corrected_income = replace_outliers_with_closest(df['income_per_cluster'])",
   "id": "6ede674164de251a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.boxplot(corrected_income)",
   "id": "9e6ff292c377a515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['income_per_cluster'] = corrected_income",
   "id": "e21e27ae2d47efb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['income_per_cluster'].is_monotonic_increasing",
   "id": "7e9b9f515e101e7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = df.sort_values(by='income_per_cluster').reset_index(drop=True)",
   "id": "7a140ebbe119a831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['income_per_cluster'].is_monotonic_increasing",
   "id": "3ef02de55f070823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.to_csv(os.path.join(root_path, 'preprocessed_df_' + model_name + '.csv'), index=False)",
   "id": "5dc2d9a14d2a4269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training - Income Prediction",
   "id": "803da94de60ff0ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "f7819b442c4a58c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig_path = os.path.join('..', 'fine_tuned_models', model_name, 'figures')\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ],
   "id": "d1ce0b9d416eb80c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = 'resnet50'\n",
    "root_path = os.path.join('..', 'fine_tuned_models', model_name, 'processed_data')\n",
    "file_path = os.path.join(root_path, 'preprocessed_df_' + model_name + '.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df.sample(10)"
   ],
   "id": "285131b987ffb63b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['income_per_cluster'].is_monotonic_increasing",
   "id": "252bf9afa6b1e785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.boxplot(df['income_per_cluster'])",
   "id": "ba722e9428746beb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X, y = df.drop('income_per_cluster', axis=1), df['income_per_cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2)\n",
    "\n",
    "# X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test = scaler.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = ridge_model.predict(X_test)\n",
    "print(f'R2 score: {r2_score(y_test, y_test_pred)}')\n",
    "\n",
    "plt.scatter(y_test, y_test_pred, alpha=.7)\n",
    "\n",
    "# Plot the perfect prediction line\n",
    "min_val = min(np.min(y_test), np.min(y_test_pred))\n",
    "max_val = max(np.max(y_test), np.max(y_test_pred))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)  # Perfect prediction line\n",
    "\n",
    "# Labeling\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "\n",
    "plt.savefig(os.path.join(fig_path, 'ridge_model'))\n",
    "plt.show()"
   ],
   "id": "6dd799440955df8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Applying K-fold",
   "id": "8270f664a1231f45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_results(tr_targets, tr_preds, te_targets, te_preds, fig_path):\n",
    "\n",
    "    # Calculate R2 scores\n",
    "    train_r2 = r2_score(tr_targets, tr_preds)\n",
    "    test_r2 = r2_score(te_targets, te_preds)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Visualize the model on the training set\n",
    "    axs[0].scatter(tr_targets, tr_preds, alpha=0.5)\n",
    "    axs[0].plot([min(tr_targets), max(tr_targets)], [min(tr_targets), max(tr_targets)], linestyle='--', color='red',\n",
    "                label='R2 line')\n",
    "    axs[0].set_xlabel('Actual Values')\n",
    "    axs[0].set_ylabel('Predicted Values')\n",
    "    axs[0].set_title(f'Training Set\\nR2: {train_r2:.2f}')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Visualize the model on the test set with R^2 score\n",
    "    axs[1].scatter(te_targets, te_preds, alpha=.5)\n",
    "    axs[1].plot([min(te_targets), max(te_targets)], [min(te_targets), max(te_targets)], linestyle='--', color='red',\n",
    "                label='R2 Line')\n",
    "    axs[1].set_xlabel('Actual Values')\n",
    "    axs[1].set_ylabel('Predicted Values')\n",
    "    axs[1].set_title(f'Test Set\\nR2 Score: {test_r2:.2f}')\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    # Show the plots\n",
    "    plt.savefig(fig_path)\n",
    "    plt.show()"
   ],
   "id": "df72b55a80b13cdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_and_test_kfold(data, fig_path_, alpha=1, k=5):\n",
    "    scaler = StandardScaler()\n",
    "    #     data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    X, y = data.drop('income_per_cluster', axis=1), data['income_per_cluster']\n",
    "\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    all_actual_test_values = []\n",
    "    all_predicted_test_values = []\n",
    "    all_actual_train_values = []\n",
    "    all_predicted_train_values = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "        y_train = scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "        y_test = scaler.transform(y_test.values.reshape(-1,1))\n",
    "\n",
    "        ridge_model.fit(X_train, y_train)\n",
    "\n",
    "        # Training set MSE and R-squared\n",
    "        y_train_pred = ridge_model.predict(X_train)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        print(f'Fold {fold} - Training Mean Squared Error: {train_mse:.4f}, Training R-squared Score: {train_r2:.4f}')\n",
    "\n",
    "        # Test set MSE and R-squared\n",
    "        y_test_pred = ridge_model.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        print(f'Fold {fold} - Test Mean Squared Error: {test_mse:.4f}, Test R-squared Score: {test_r2:.4f}\\n')\n",
    "\n",
    "        # Save actual and predicted values\n",
    "        all_actual_test_values.extend(y_test)\n",
    "        all_predicted_test_values.extend(y_test_pred)\n",
    "        all_actual_train_values.extend(y_train)\n",
    "        all_predicted_train_values.extend(y_train_pred)\n",
    "\n",
    "    # Overall R-squared\n",
    "    overall_r2 = r2_score(all_actual_train_values, all_predicted_train_values)\n",
    "    print(f'Overall/Average train R-squared Score: {overall_r2:.4f}\\n')\n",
    "    overall_r2 = r2_score(all_actual_test_values, all_predicted_test_values)\n",
    "    print(f'Overall/Average train R-squared Score: {overall_r2:.4f}\\n')\n",
    "\n",
    "    fig_save_path = os.path.join(fig_path_)\n",
    "\n",
    "    visualize_results(\n",
    "        all_actual_train_values,\n",
    "        all_predicted_train_values,\n",
    "        all_actual_test_values,\n",
    "        all_predicted_test_values,\n",
    "        fig_save_path\n",
    "    )"
   ],
   "id": "a88996ae3ab215d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_and_test_kfold(df, os.path.join(fig_path, 'kfold_ridge'), alpha=1)",
   "id": "748bae4c39d99b72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using Vanilla Neural Network",
   "id": "4a0b617fab9c2793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import KFold"
   ],
   "id": "53c308b4e9894e3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "root_path = os.path.join('..', 'fine_tuned_models', model_name, 'processed_data')\n",
    "file_path = os.path.join(root_path, 'preprocessed_df_' + model_name + '.csv')\n",
    "df = pd.read_csv(file_path)"
   ],
   "id": "8f6d774d40020313"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = 'resnet50'\n",
    "model_path = os.path.join('..', 'fine_tuned_models', model_name)"
   ],
   "id": "738afedd6b076548"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the neural network model\n",
    "class SimpleRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "id": "3aa4aeed0b8d0ae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_and_create_dataloader_kfold(X, y, b_size=16):\n",
    "    # Apply standard scaling\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Apply scaling to features\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1,1))\n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    X_tensor = torch.FloatTensor(X.values)\n",
    "    y_tensor = torch.FloatTensor(y_scaled)  # Reshape to ensure it's a column vector\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "    return dataloader, X_tensor.shape[1], scaler"
   ],
   "id": "6278a52be4f453c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training function\n",
    "def train(loader_train, loader_val, input_size, device, num_epochs=20, set_seed=False, lr=0.001, visualize=True, print_rslts=True):\n",
    "    if set_seed:\n",
    "        # Set random seeds for reproducibility\n",
    "        seed = 42\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Instantiate the model, define loss function, and optimizer\n",
    "    model = SimpleRegressionModel(input_size=input_size).to(device)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    #     criterion = nn.MSELoss()\n",
    "    #     optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_weights = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_x, batch_y in loader_train:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(loader_train)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_x, val_y in loader_val:\n",
    "                val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "                val_outputs = model(val_x)\n",
    "                val_loss += criterion(val_outputs, val_y).item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(loader_val)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "\n",
    "        if print_rslts:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    if visualize:\n",
    "        # Visualize the Error lines\n",
    "        plt.plot(range(1, num_epochs + 1), train_losses, color='red', marker='o', label='Train Error')\n",
    "        plt.plot(range(1, num_epochs + 1), val_losses, color='blue', marker='o', label='Val Error')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Error During Training and Validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "    return model, best_val_loss"
   ],
   "id": "7e4fb46be3bd368f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluation function\n",
    "def evaluate(loader_test, model, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.L1Loss()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            all_predictions.extend(outputs.detach().cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader_test)\n",
    "    return all_targets, all_predictions, avg_loss"
   ],
   "id": "7e7283e685d4d242"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# K-fold cross-validation function with print statement for best model\n",
    "def k_fold_cross_validation(df, figure_path, model_path, print_rslts=False, visualize=False, k=5, num_epochs=20, lr=0.001, batch_size=16):\n",
    "    # Get features and target\n",
    "    X, y = df.drop('income_per_cluster', axis=1), df['income_per_cluster']\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    all_train_targets = []\n",
    "    all_train_predictions = []\n",
    "    all_test_targets = []\n",
    "    all_test_predictions = []\n",
    "    all_test_r2 = []\n",
    "    all_train_r2 = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    best_fold = -1\n",
    "    scaler = None\n",
    "\n",
    "    # Define device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Preprocess and create data loaders\n",
    "        train_loader, size_input, scaler = preprocess_and_create_dataloader_kfold(X_train, y_train, b_size=batch_size)\n",
    "        val_loader, _, _ = preprocess_and_create_dataloader_kfold(X_val, y_val, b_size=batch_size)\n",
    "\n",
    "        # Train the model\n",
    "        trained_model, fold_best_val_loss = train(loader_train=train_loader, loader_val=val_loader,\n",
    "                                                  input_size=size_input, device=device, num_epochs=num_epochs, lr=lr,\n",
    "                                                  print_rslts=print_rslts, visualize=visualize)\n",
    "\n",
    "        # Check if this fold's model is the best one\n",
    "        if fold_best_val_loss < best_val_loss:\n",
    "            best_val_loss = fold_best_val_loss\n",
    "            best_model = trained_model\n",
    "            best_fold = fold_idx + 1  # Folds are 0-indexed, so add 1 for display\n",
    "            print(f\"Best model updated at fold {best_fold} with validation loss: {best_val_loss}\")\n",
    "\n",
    "        # Evaluate the model on train data\n",
    "        train_targets, train_predictions, _ = evaluate(loader_test=train_loader, model=trained_model, device=device)\n",
    "        train_r2 = r2_score(train_targets, train_predictions)\n",
    "        all_train_targets.extend(train_targets)\n",
    "        all_train_predictions.extend(train_predictions)\n",
    "        all_train_r2.append(train_r2)\n",
    "\n",
    "        # Evaluate the model on validation data\n",
    "        val_targets, val_predictions, _ = evaluate(loader_test=val_loader, model=trained_model, device=device)\n",
    "        val_r2 = r2_score(val_targets, val_predictions)\n",
    "        all_test_targets.extend(val_targets)\n",
    "        all_test_predictions.extend(val_predictions)\n",
    "        all_test_r2.append(val_r2)\n",
    "\n",
    "        print(f\"Fold {fold_idx + 1} - Training Mean Squared Error: {mean_squared_error(train_targets, train_predictions)}, Training R-squared Score: {train_r2:.2f}\")\n",
    "        print(f\"Fold {fold_idx + 1} - Validation Mean Squared Error: {mean_squared_error(val_targets, val_predictions)}, Validation R-squared Score: {val_r2:.2f}\\n\")\n",
    "\n",
    "    print(f'Average Validation R2: {np.mean(all_test_r2):.2f}')\n",
    "    print(f'Average Train R2: {np.mean(all_train_r2):.2f}')\n",
    "\n",
    "    visualize_results(all_train_targets, all_train_predictions, all_test_targets, all_test_predictions, fig_path=figure_path)\n",
    "\n",
    "    # Save the best model\n",
    "    best_model_path = os.path.join(model_path, 'best_Regression_model.pth')\n",
    "    torch.save(best_model, best_model_path)\n",
    "    print(f'Best model from fold {best_fold} saved to {best_model_path}')\n",
    "\n",
    "    scaler_path = os.path.join(model_path, 'scaler.pkl')\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f'Scaler saved to {scaler_path}')\n",
    "\n",
    "    return all_train_targets, all_train_predictions, all_test_targets, all_test_predictions"
   ],
   "id": "f096a4b23daea267"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Perform k-fold cross-validation\n",
    "train_targets, train_predictions, test_targets, test_predictions = k_fold_cross_validation(df, figure_path=os.path.join(fig_path, model_name+'_NN'), model_path=model_path, num_epochs=150, batch_size=16)"
   ],
   "id": "b503b9917edbb660"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
